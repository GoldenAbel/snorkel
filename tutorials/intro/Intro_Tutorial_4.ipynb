{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro. to Snorkel: Extracting Spouse Relations from the News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Training a Model with Data Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the tutorial, we will train a statistical model to differentiate between true and false `Spouse` mentions.\n",
    "\n",
    "We will train this model using _data programming_, and we will **ignore** the training labels provided with the training data. This is a more realistic scenario; in the wild, hand-labeled training data is rare and expensive. Data programming enables us to train a model using only a modest amount of hand-labeled data for validation and testing. For more information on data programming, see the [NIPS 2016 paper](https://arxiv.org/abs/1605.07723)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our definition of the `Spouse` `Candidate` subclass from Parts II and III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading `CandidateSet` objects\n",
    "\n",
    "We reload the training and development `CandidateSet` objects from the previous parts of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'News Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'News Development Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Creating Features\n",
    "Recall that our goal is to distinguish between true and false mentions of spouse relations. To train a model for this task, we first embed our `Spouse` candidates in a feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 11min 55s, sys: 7.09 s, total: 12min 2s\n",
      "Wall time: 12min 20s\n"
     ]
    }
   ],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.1 s, sys: 129 ms, total: 4.23 s\n",
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%time F_train = feature_manager.load(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the `scipy.sparse.csr_matrix` class, with some special features which we demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4698x115172 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 272417 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spouse(Span(\"Elijah E. Cummings\", parent=15829, chars=[17,34], words=[3,5]), Span(\"Obama\", parent=15829, chars=[137,141], words=[23,23]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train.get_candidate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnotationKey (TDL_LEMMA:PARENTS-OF-BETWEEN-MENTION-and-MENTION[None])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train.get_key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Labeling Functions\n",
    "Labeling functions are a core tool of data programming. They are heuristic functions that aim to classify candidates correctly. Their outputs will be automatically combined and denoised to estimate the probabilities of training labels for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens, get_between_tokens, get_text_between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Labeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct a `LabelManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the `LabelManager` to to apply the labeling functions to the training `CandidateSet`.  We'll start with some of our labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spouses = {'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "family = family | {f + '-in-law' for f in family}\n",
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "def LF_too_far_apart(c):\n",
    "    return -1 if len(get_between_tokens(c)) > 10 else 0\n",
    "\n",
    "def LF_third_wheel(c):\n",
    "    return -1 if 'PERSON' in get_between_tokens(c, attrib='ner_tags', case_sensitive=True) else 0\n",
    "    \n",
    "def LF_husband_wife(c):\n",
    "    return 1 if len(spouses.intersection(set(get_between_tokens(c)))) > 0 else 0\n",
    "\n",
    "def LF_husband_wife_left_window(c):\n",
    "    if len(spouses.intersection(set(get_left_tokens(c[0], window=2)))) > 0:\n",
    "        return 1\n",
    "    elif len(spouses.intersection(set(get_left_tokens(c[1], window=2)))) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_no_spouse_in_sentence(c):\n",
    "    return -1 if len(spouses.intersection(set(c[0].parent.words))) == 0 else 0\n",
    "\n",
    "def LF_and_married(c):\n",
    "    return 1 if 'and' in get_between_tokens(c) and 'married' in get_right_tokens(c) else 0\n",
    "    \n",
    "def LF_familial_relationship(c):\n",
    "    return -1 if len(set(family).intersection(set(get_between_tokens(c)))) > 0 else 0\n",
    "\n",
    "def LF_family_left_window(c):\n",
    "    if len(family.intersection(set(get_left_tokens(c[0], window=2)))) > 0:\n",
    "        return -1\n",
    "    elif len(family.intersection(set(get_left_tokens(c[1], window=2)))) > 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_other_relationship(c):\n",
    "    coworker = ['boss', 'employee', 'secretary', 'co-worker']\n",
    "    return -1 if len(set(coworker).intersection(set(get_between_tokens(c)))) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs = [LF_too_far_apart, LF_third_wheel, LF_husband_wife, LF_husband_wife_left_window,\n",
    "       LF_and_married, LF_familial_relationship, LF_other_relationship]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 49.3 s, sys: 809 ms, total: 50.1 s\n",
      "Wall time: 50.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4698x7 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 3570 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** load if we've already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 108 ms, sys: 2.41 ms, total: 111 ms\n",
      "Wall time: 118 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4698x7 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 3570 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = label_manager.load(session, train, 'LF Labels')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add or rerun a single labeling function (or more!) with the below command. Note that we set the argument `expand_key_set` to `True` to indicate that the set of matrix columns should be allowed to expand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4698x8 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 7930 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train = label_manager.update(session, train, 'LF Labels', True, f=[LF_no_spouse_in_sentence])\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view statistics about the resulting label matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflicts</th>\n",
       "      <th>coverage</th>\n",
       "      <th>j</th>\n",
       "      <th>overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_too_far_apart</th>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.279268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_third_wheel</th>\n",
       "      <td>0.021499</td>\n",
       "      <td>0.379736</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_husband_wife</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.025117</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_husband_wife_left_window</th>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.029161</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_and_married</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_familial_relationship</th>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_relationship</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>6</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_no_spouse_in_sentence</th>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.928054</td>\n",
       "      <td>7</td>\n",
       "      <td>0.458067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             conflicts  coverage  j  overlaps\n",
       "LF_too_far_apart              0.016603  0.279268  0  0.276926\n",
       "LF_third_wheel                0.021499  0.379736  1  0.375692\n",
       "LF_husband_wife               0.018519  0.025117  2  0.024053\n",
       "LF_husband_wife_left_window   0.014900  0.029161  3  0.020434\n",
       "LF_and_married                0.000213  0.000213  4  0.000213\n",
       "LF_familial_relationship      0.006386  0.040230  5  0.037463\n",
       "LF_other_relationship         0.000000  0.006173  6  0.006173\n",
       "LF_no_spouse_in_sentence      0.000213  0.928054  7  0.458067"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Generative Model\n",
    "We estimate the accuracies of the labeling functions without supervision. Specifically, we estimate the parameters of a `NaiveBayes` generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4698\n",
      "Features:\t\t\t8\n",
      "================================================================================\n",
      "Begin training for rate=1e-05, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.414672\n",
      "\tLearning epoch = 250\tGradient mag. = 0.436693\n",
      "\tLearning epoch = 500\tGradient mag. = 0.436889\n",
      "\tLearning epoch = 750\tGradient mag. = 0.437085\n",
      "Final gradient magnitude for rate=1e-05, mu=1e-06: 0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1318: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=1000, rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.save(session, 'Generative Params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00215399,  1.0025843 ,  0.99987012,  0.99992132,  0.99999873,\n",
       "        1.00025635,  1.00006087,  1.00277025])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model\n",
    "We use the estimated probabilites to train a discriminative model that classifies each `Candidate` as a true or false mention. We'll use a random hyperparameter search, evaluated on the development set labels, to find the best hyperparameters for our model. To run a hyperparameter search, we need labels for a development set. If they aren't already available, we can manually create labels using the Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "from snorkel.learning_utils import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "iter_param = ListParameter('n_iter', [250, 500, 1000, 2000])\n",
    "rate_param = RangeParameter('rate', 1e-4, 1e-2, step=0.75, log_base=10)\n",
    "reg_param  = RangeParameter('mu', 1e-8, 1e-2, step=1, log_base=10)\n",
    "\n",
    "disc_model = LogReg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create features for the development set candidates.\n",
    "\n",
    "Note that we use the training feature set, because those are the only features for which we have learned parameters. Features that were not encountered during training, e.g., a token that does not appear in the training set, are ignored, because we do not have any information about them.\n",
    "\n",
    "To do so with the `FeatureManager`, we call update with the new `CandidateSet`, the name of the training `AnnotationKeySet`, and the value `False` for the parameter `extend_key_set` to indicate that the `AnnotationKeySet` should not be expanded with new `Feature` keys encountered during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 24.1 s, sys: 462 ms, total: 24.5 s\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 97.1 ms, total: 2.28 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the development set labels and gold candidates we made in Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_gold_dev = label_manager.load(session, dev, \"News Gold Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_dev_set = session.query(CandidateSet).filter(CandidateSet.name == 'News Development Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up and run the hyperparameter search, training our model with different hyperparamters and picking the best model configuration to keep. We'll set the random seed to maintain reproducibility.\n",
    "\n",
    "Note that we are fitting our model's parameters to the training set generated by our labeling functions, while we are picking hyperparamters with respect to score over the development set labels which we created by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searcher = RandomSearch(disc_model, F_train, train_marginals, 10, iter_param, rate_param, reg_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing n_iter = 1.00e+03, rate = 1.00e-04, mu = 1.00e-02\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.0001\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 9.04792147114e-05\n",
      "\tLoss = 2185.689909\tGradient magnitude = 63.544320\n",
      "\tLearning epoch = 200\tStep size = 8.18648829479e-05\n",
      "\tLoss = 2159.912231\tGradient magnitude = 48.567846\n",
      "\tLearning epoch = 300\tStep size = 7.40707032156e-05\n",
      "\tLoss = 2145.210919\tGradient magnitude = 40.411948\n",
      "\tLearning epoch = 400\tStep size = 6.70185906007e-05\n",
      "\tLoss = 2135.616472\tGradient magnitude = 35.318976\n",
      "\tLearning epoch = 500\tStep size = 6.06378944861e-05\n",
      "\tLoss = 2128.823323\tGradient magnitude = 31.842154\n",
      "\tLearning epoch = 600\tStep size = 5.48646907485e-05\n",
      "\tLoss = 2123.752776\tGradient magnitude = 29.314160\n",
      "\tLearning epoch = 700\tStep size = 4.96411413431e-05\n",
      "\tLoss = 2119.827388\tGradient magnitude = 27.394050\n",
      "\tLearning epoch = 800\tStep size = 4.4914914861e-05\n",
      "\tLoss = 2116.706181\tGradient magnitude = 25.889402\n",
      "\tLearning epoch = 900\tStep size = 4.06386622545e-05\n",
      "\tLoss = 2114.173211\tGradient magnitude = 24.682356\n",
      "============================================================\n",
      "Testing n_iter = 2.50e+02, rate = 3.16e-03, mu = 1.00e-06\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.00316227766017\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 0.00286120399391\n",
      "\tLoss = 2424.271497\tGradient magnitude = 648.322551\n",
      "\tLearning epoch = 200\tStep size = 0.00258879490498\n",
      "\tLoss = 3028.684601\tGradient magnitude = 828.166944\n",
      "============================================================\n",
      "Testing n_iter = 1.00e+03, rate = 1.00e-04, mu = 1.00e-07\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.0001\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 9.04792147114e-05\n",
      "\tLoss = 2184.721340\tGradient magnitude = 63.408203\n",
      "\tLearning epoch = 200\tStep size = 8.18648829479e-05\n",
      "\tLoss = 2158.378832\tGradient magnitude = 48.342676\n",
      "\tLearning epoch = 300\tStep size = 7.40707032156e-05\n",
      "\tLoss = 2143.278136\tGradient magnitude = 40.135618\n",
      "\tLearning epoch = 400\tStep size = 6.70185906007e-05\n",
      "\tLoss = 2133.381137\tGradient magnitude = 35.011150\n",
      "\tLearning epoch = 500\tStep size = 6.06378944861e-05\n",
      "\tLoss = 2126.348626\tGradient magnitude = 31.511694\n",
      "\tLearning epoch = 600\tStep size = 5.48646907485e-05\n",
      "\tLoss = 2121.083598\tGradient magnitude = 28.966247\n",
      "\tLearning epoch = 700\tStep size = 4.96411413431e-05\n",
      "\tLoss = 2116.996849\tGradient magnitude = 27.032182\n",
      "\tLearning epoch = 800\tStep size = 4.4914914861e-05\n",
      "\tLoss = 2113.739593\tGradient magnitude = 25.516094\n",
      "\tLearning epoch = 900\tStep size = 4.06386622545e-05\n",
      "\tLoss = 2111.090383\tGradient magnitude = 24.299643\n",
      "============================================================\n",
      "Testing n_iter = 1.00e+03, rate = 3.16e-03, mu = 1.00e-08\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.00316227766017\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 0.00286120399391\n",
      "\tLoss = 2151.526692\tGradient magnitude = 389.417511\n",
      "\tLearning epoch = 200\tStep size = 0.00258879490498\n",
      "\tLoss = 2288.471160\tGradient magnitude = 839.120846\n",
      "\tLearning epoch = 300\tStep size = 0.00234232130052\n",
      "\tLoss = 2231.009843\tGradient magnitude = 727.491583\n",
      "\tLearning epoch = 400\tStep size = 0.00211931391872\n",
      "\tLoss = 2162.963210\tGradient magnitude = 563.232211\n",
      "\tLearning epoch = 500\tStep size = 0.00191753859093\n",
      "\tLoss = 2113.358981\tGradient magnitude = 415.021710\n",
      "\tLearning epoch = 600\tStep size = 0.00173497385886\n",
      "\tLoss = 2060.834127\tGradient magnitude = 139.122035\n",
      "\tLearning epoch = 700\tStep size = 0.00156979072295\n",
      "\tLoss = 2053.121336\tGradient magnitude = 1.662044\n",
      "\tLearning epoch = 800\tStep size = 0.00142033431873\n",
      "\tLoss = 2052.765953\tGradient magnitude = 1.440032\n",
      "\tLearning epoch = 900\tStep size = 0.00128510733787\n",
      "\tLoss = 2052.512289\tGradient magnitude = 1.304848\n",
      "============================================================\n",
      "Testing n_iter = 1.00e+03, rate = 3.16e-03, mu = 1.00e-03\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.00316227766017\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 0.00286120399391\n",
      "\tLoss = 2495.250622\tGradient magnitude = 1176.929244\n",
      "\tLearning epoch = 200\tStep size = 0.00258879490498\n",
      "\tLoss = 3019.133501\tGradient magnitude = 826.214375\n",
      "\tLearning epoch = 300\tStep size = 0.00234232130052\n",
      "\tLoss = 2356.101317\tGradient magnitude = 611.330073\n",
      "\tLearning epoch = 400\tStep size = 0.00211931391872\n",
      "\tLoss = 2285.379873\tGradient magnitude = 564.230077\n",
      "\tLearning epoch = 500\tStep size = 0.00191753859093\n",
      "\tLoss = 2154.766201\tGradient magnitude = 416.218473\n",
      "\tLearning epoch = 600\tStep size = 0.00173497385886\n",
      "\tLoss = 2063.107858\tGradient magnitude = 140.507100\n",
      "\tLearning epoch = 700\tStep size = 0.00156979072295\n",
      "\tLoss = 2053.963413\tGradient magnitude = 1.682721\n",
      "\tLearning epoch = 800\tStep size = 0.00142033431873\n",
      "\tLoss = 2053.614996\tGradient magnitude = 1.468595\n",
      "\tLearning epoch = 900\tStep size = 0.00128510733787\n",
      "\tLoss = 2053.366825\tGradient magnitude = 1.337123\n",
      "============================================================\n",
      "Testing n_iter = 2.00e+03, rate = 1.00e-04, mu = 1.00e-03\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.0001\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 9.04792147114e-05\n",
      "\tLoss = 2184.819484\tGradient magnitude = 63.421714\n",
      "\tLearning epoch = 200\tStep size = 8.18648829479e-05\n",
      "\tLoss = 2158.534846\tGradient magnitude = 48.365062\n",
      "\tLearning epoch = 300\tStep size = 7.40707032156e-05\n",
      "\tLoss = 2143.475245\tGradient magnitude = 40.163038\n",
      "\tLearning epoch = 400\tStep size = 6.70185906007e-05\n",
      "\tLoss = 2133.609474\tGradient magnitude = 35.041602\n",
      "\tLearning epoch = 500\tStep size = 6.06378944861e-05\n",
      "\tLoss = 2126.601755\tGradient magnitude = 31.544314\n",
      "\tLearning epoch = 600\tStep size = 5.48646907485e-05\n",
      "\tLoss = 2121.356891\tGradient magnitude = 29.000522\n",
      "\tLearning epoch = 700\tStep size = 4.96411413431e-05\n",
      "\tLoss = 2117.286905\tGradient magnitude = 27.067759\n",
      "\tLearning epoch = 800\tStep size = 4.4914914861e-05\n",
      "\tLoss = 2114.043795\tGradient magnitude = 25.552729\n",
      "\tLearning epoch = 900\tStep size = 4.06386622545e-05\n",
      "\tLoss = 2111.406622\tGradient magnitude = 24.337152\n",
      "\tLearning epoch = 1000\tStep size = 3.67695424771e-05\n",
      "\tLoss = 2109.227684\tGradient magnitude = 23.344049\n",
      "\tLearning epoch = 1100\tStep size = 3.32687932862e-05\n",
      "\tLoss = 2107.404030\tGradient magnitude = 22.520938\n",
      "\tLearning epoch = 1200\tStep size = 3.01013429093e-05\n",
      "\tLoss = 2105.861498\tGradient magnitude = 21.830645\n",
      "\tLearning epoch = 1300\tStep size = 2.72354586819e-05\n",
      "\tLoss = 2104.545213\tGradient magnitude = 21.246043\n",
      "\tLearning epoch = 1400\tStep size = 2.46424291385e-05\n",
      "\tLoss = 2103.413666\tGradient magnitude = 20.746861\n",
      "\tLearning epoch = 1500\tStep size = 2.22962763703e-05\n",
      "\tLoss = 2102.434813\tGradient magnitude = 20.317626\n",
      "\tLearning epoch = 1600\tStep size = 2.01734957697e-05\n",
      "\tLoss = 2101.583498\tGradient magnitude = 19.946317\n",
      "\tLearning epoch = 1700\tStep size = 1.82528205523e-05\n",
      "\tLoss = 2100.839688\tGradient magnitude = 19.623451\n",
      "\tLearning epoch = 1800\tStep size = 1.65150086984e-05\n",
      "\tLoss = 2100.187211\tGradient magnitude = 19.341444\n",
      "\tLearning epoch = 1900\tStep size = 1.49426501798e-05\n",
      "\tLoss = 2099.612863\tGradient magnitude = 19.094161\n",
      "============================================================\n",
      "Testing n_iter = 2.00e+03, rate = 3.16e-03, mu = 1.00e-04\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.00316227766017\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 0.00286120399391\n",
      "\tLoss = 2284.146791\tGradient magnitude = 784.625476\n",
      "\tLearning epoch = 200\tStep size = 0.00258879490498\n",
      "\tLoss = 2109.002239\tGradient magnitude = 285.955479\n",
      "\tLearning epoch = 300\tStep size = 0.00234232130052\n",
      "\tLoss = 2179.586282\tGradient magnitude = 585.533456\n",
      "\tLearning epoch = 400\tStep size = 0.00211931391872\n",
      "\tLoss = 2163.002828\tGradient magnitude = 563.058051\n",
      "\tLearning epoch = 500\tStep size = 0.00191753859093\n",
      "\tLoss = 2113.422666\tGradient magnitude = 414.923129\n",
      "\tLearning epoch = 600\tStep size = 0.00173497385886\n",
      "\tLoss = 2060.914764\tGradient magnitude = 139.060468\n",
      "\tLearning epoch = 700\tStep size = 0.00156979072295\n",
      "\tLoss = 2053.207357\tGradient magnitude = 1.665296\n",
      "\tLearning epoch = 800\tStep size = 0.00142033431873\n",
      "\tLoss = 2052.852155\tGradient magnitude = 1.443093\n",
      "\tLearning epoch = 900\tStep size = 0.00128510733787\n",
      "\tLoss = 2052.598877\tGradient magnitude = 1.307789\n",
      "\tLearning epoch = 1000\tStep size = 0.0011627550275\n",
      "\tLoss = 2052.406769\tGradient magnitude = 1.209780\n",
      "\tLearning epoch = 1100\tStep size = 0.0010520516179\n",
      "\tLoss = 2052.256133\tGradient magnitude = 1.133825\n",
      "\tLearning epoch = 1200\tStep size = 0.000951888042233\n",
      "\tLoss = 2052.135323\tGradient magnitude = 1.072841\n",
      "\tLearning epoch = 1300\tStep size = 0.000861260825544\n",
      "\tLoss = 2052.036762\tGradient magnitude = 1.022781\n",
      "\tLearning epoch = 1400\tStep size = 0.000779262031569\n",
      "\tLoss = 2051.955245\tGradient magnitude = 0.981049\n",
      "\tLearning epoch = 1500\tStep size = 0.000705070166707\n",
      "\tLoss = 2051.887060\tGradient magnitude = 0.945849\n",
      "\tLearning epoch = 1600\tStep size = 0.000637941950001\n",
      "\tLoss = 2051.829482\tGradient magnitude = 0.915883\n",
      "\tLearning epoch = 1700\tStep size = 0.000577204866675\n",
      "\tLoss = 2051.780465\tGradient magnitude = 0.890176\n",
      "\tLearning epoch = 1800\tStep size = 0.000522250430643\n",
      "\tLoss = 2051.738443\tGradient magnitude = 0.867982\n",
      "\tLearning epoch = 1900\tStep size = 0.000472528088473\n",
      "\tLoss = 2051.702200\tGradient magnitude = 0.848717\n",
      "============================================================\n",
      "Testing n_iter = 5.00e+02, rate = 1.78e-02, mu = 1.00e-07\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.0177827941004\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 0.0160897324558\n",
      "\tLoss = 15151.351554\tGradient magnitude = 2815.242288\n",
      "\tLearning epoch = 200\tStep size = 0.0145578635751\n",
      "\tLoss = 19362.336209\tGradient magnitude = 2542.529668\n",
      "\tLearning epoch = 300\tStep size = 0.0131718406415\n",
      "\tLoss = 29626.133443\tGradient magnitude = 1018.185012\n",
      "\tLearning epoch = 400\tStep size = 0.0119177779755\n",
      "\tLoss = 23960.076534\tGradient magnitude = 1670.257401\n",
      "============================================================\n",
      "Testing n_iter = 2.50e+02, rate = 3.16e-03, mu = 1.00e-04\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.00316227766017\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 0.00286120399391\n",
      "\tLoss = 2284.146791\tGradient magnitude = 784.625476\n",
      "\tLearning epoch = 200\tStep size = 0.00258879490498\n",
      "\tLoss = 2109.002239\tGradient magnitude = 285.955479\n",
      "============================================================\n",
      "Testing n_iter = 2.50e+02, rate = 1.78e-02, mu = 1.00e-05\n",
      "============================================================\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t4598\n",
      "Features:\t\t\t115172\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.0177827941004\n",
      "\tLoss = 3187.090736\tGradient magnitude = 1822.322773\n",
      "\tLearning epoch = 100\tStep size = 0.0160897324558\n",
      "\tLoss = 38717.424904\tGradient magnitude = 1384.617928\n",
      "\tLearning epoch = 200\tStep size = 0.0145578635751\n",
      "\tLoss = 39559.853537\tGradient magnitude = 1092.500235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_iter</th>\n",
       "      <th>rate</th>\n",
       "      <th>mu</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>0.017783</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.163265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250</td>\n",
       "      <td>0.017783</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_iter      rate            mu     Prec.      Rec.        F1\n",
       "0    1000  0.000100  1.000000e-02  0.000000  0.000000  0.000000\n",
       "1     250  0.003162  1.000000e-06  0.500000  0.166667  0.250000\n",
       "2    1000  0.000100  1.000000e-07  0.000000  0.000000  0.000000\n",
       "3    1000  0.003162  1.000000e-08  0.600000  0.500000  0.545455\n",
       "4    1000  0.003162  1.000000e-03  0.600000  0.500000  0.545455\n",
       "5    2000  0.000100  1.000000e-03  1.000000  0.166667  0.285714\n",
       "6    2000  0.003162  1.000000e-04  0.600000  0.500000  0.545455\n",
       "7     500  0.017783  1.000000e-07  0.093023  0.666667  0.163265\n",
       "8     250  0.003162  1.000000e-04  0.100000  0.500000  0.166667\n",
       "9     250  0.017783  1.000000e-05  0.333333  0.166667  0.222222"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "searcher.fit(F_dev, L_gold_dev, gold_dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note that to train a model without tuning any hyperparameters--at your own risk!--just use the `train` method of the discriminative model. For instance, to train with 500 iterations and a learning rate of 0.001, you could run:_\n",
    "```\n",
    "disc_model.train(F_train, train_marginals, n_iter=500, rate=0.001)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115172,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 690 ms, total: 26.1 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration plot:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEZCAYAAABFFVgWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e4e1810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Test set size:\t224\n",
      "----------------------------------------\n",
      "Pos. class accuracy: 0.5\n",
      "Neg. class accuracy: 0.990825688073\n",
      "----------------------------------------\n",
      "Precision:\t0.6\n",
      "Recall:\t\t0.5\n",
      "F1 Score:\t0.545454545455\n",
      "----------------------------------------\n",
      "TP: 3 | FP: 2 | TN: 216 | FN: 3\n",
      "========================================\n",
      "========================================\n",
      "Recall-corrected Noise-aware Model\n",
      "========================================\n",
      "Pos. class accuracy: 0.5\n",
      "Neg. class accuracy: 0.990825688073\n",
      "Corpus Precision 0.6\n",
      "Corpus Recall    0.5\n",
      "Corpus F1        0.545\n",
      "----------------------------------------\n",
      "TP: 3 | FP: 2 | TN: 216 | FN: 3\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_dev, L_gold_dev, gold_dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Examples\n",
    "After evaluating on the development `CandidateSet`, the labeling functions can be modified. Try changing the labeling functions to improve performance. You can view the true positives, false positives, true negatives, and false negatives using the `Viewer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"jupyter-js-widgets\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# NOTE: This if-then statement is only to avoid opening the viewer during automated testing of this notebook\n",
    "# You should ignore this!\n",
    "import os\n",
    "if 'CI' not in os.environ:\n",
    "    sv = SentenceNgramViewer(fn, session, annotator_name=\"Tutorial Part IV User\")\n",
    "else:\n",
    "    sv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    }
   ],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part V, we will test our model on the test `CandidateSet`."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {
    "ee9ffcb4d3e84b3c900472a7e043277a": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
