{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Tagging Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* diseases from Pubmed abstracts, using annotations from the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial, which has 5 parts, walks through the process of constructing a model to classify _candidate_ disease mentions as either true (i.e., that it is truly a mention of a disease) or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Training a Model with Data Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the tutorial, we will train a statistical model to differentiate between true and false `Disease` mentions.\n",
    "\n",
    "We will train this model using _data programming_, and we will **ignore** the training labels provided with the training data. This is a more realistic scenario; in the wild, hand-labeled training data is rare and expensive. Data programming enables us to train a model using only a modest amount of hand-labeled data for validation and testing. For more information on data programming, see the [NIPS 2016 paper](https://arxiv.org/abs/1605.07723)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our definition of the `Disease` `Candidate` subclass from Parts II and III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading `CandidateSet` objects\n",
    "\n",
    "We reload the training and development `CandidateSet` objects from the previous parts of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Creating Features\n",
    "Recall that our goal is to distinguish between true and false mentions of chemical-disease relations. To train a model for this task, we first embed our `ChemicalDisease` candidates in a feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 25min 32s, sys: 31.9 s, total: 26min 3s\n",
      "Wall time: 26min 1s\n"
     ]
    }
   ],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.load(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the `scipy.sparse.csr_matrix` class, with some special features which we demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30067x498874 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1452926 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disease(Span(\"dose\", parent=2181, chars=[2,5], words=[1,1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train.get_candidate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnotationKey (DDL_WORD_SEQ_[dose])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train.get_key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Labeling Functions\n",
    "Labeling functions are a core tool of data programming. They are heuristic functions that aim to classify candidates correctly. Their outputs will be automatically combined and denoised to estimate the probabilities of training labels for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from lf_terms import *\n",
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load some publicly-available biomedical dictionaries, which we will leverage in some of our LFs below as a source of weak supervision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "umls_dict              = load_umls_dictionary()\n",
    "chemicals              = load_chemdner_dictionary()\n",
    "abbrv2text, text2abbrv = load_specialist_abbreviations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document-Level Labeling Functions\n",
    "We start with some labeling functions that label candidates based on document-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_doc_candidate_spans\n",
    "\n",
    "def LF_undefined_abbreviation(c):\n",
    "    '''Candidate is a known abbreviation, but no corresponding full name in document'''\n",
    "    doc_spans = get_doc_candidate_spans(c)\n",
    "    phrase = c[0].get_span().lower()\n",
    "    mentions = set([s.get_span().lower() for s in doc_spans])\n",
    "    if len(phrase) > 1 and phrase in abbrv2text and not set(abbrv2text[phrase].keys()).intersection(mentions):\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence-Level Labeling Functions\n",
    "We also include some labeling functions that label candidates based on sentence-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_sent_candidate_spans\n",
    "\n",
    "def LF_contiguous_mentions(c):\n",
    "    '''Contiguous candidates are likely wrong'''\n",
    "    neighbor_spans = get_sent_candidate_spans(c)\n",
    "    start, end = c[0].get_word_start(), c[0].get_word_end()\n",
    "    for s in neighbor_spans:\n",
    "        if s.get_word_end() + 1 == start or s.get_word_start() - 1 == end:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mention-Level Labeling Functions\n",
    "We now define a number of labeling functions that label candidates based on attributes related to the mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens\n",
    "\n",
    "def LF_tumors_growths(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"^(\\w* ){0,2}(['] )*(tumor|tumour|polyp|pilomatricoma|cyst|lipoma)$\", phrase) else 0\n",
    "\n",
    "def LF_cancer(c):\n",
    "    '''<TYPE> cancer'''\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"\\w* cancer\",phrase) else 0\n",
    "\n",
    "def LF_disease_syndrome(c):\n",
    "    '''<TYPE> disease or <TYPE> syndrome'''\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"\\w* (disease|syndrome)+\",phrase) else 0\n",
    "\n",
    "def LF_indicators(c):\n",
    "    '''Indicator words'''\n",
    "    return 1 if \" \".join(c[0].get_attrib_tokens()).lower() in indicators else 0\n",
    "\n",
    "def LF_common_disease(c):\n",
    "    '''Common disease'''\n",
    "    return 1 if \" \".join(c[0].get_attrib_tokens()).lower() in common_disease else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For a few more examples of LFs of this style that we'll use, see [Disease_Tagging_Tutorial_LFs.py](Disease_Tagging_Tutorial_LFs.py).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary Labeling Functions\n",
    "We can use existing dictionaries for distant supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_SNOWMED_CT_sign_or_symptom(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"snomedct\"][\"sign_or_symptom\"] else 0\n",
    "\n",
    "def LF_SNOWMED_CT_disease_or_syndrome(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"snomedct\"][\"disease_or_syndrome\"] else 0\n",
    "\n",
    "def LF_MESH_disease_or_syndrome(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"mesh\"][\"disease_or_syndrome\"] else 0\n",
    "\n",
    "def LF_MESH_sign_or_symptom(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"mesh\"][\"sign_or_symptom\"] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Labeling Functions\n",
    "When writing labeling functions, it is important to provide negative supervision in addition to positive supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_organs(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in organs else 0      \n",
    "\n",
    "def LF_chemical_name(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens())\n",
    "    return -1 if phrase in chemicals and not phrase.isupper() else 0\n",
    "\n",
    "def LF_bodysym(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in bodysym else 0  \n",
    "\n",
    "def LF_protein_chemical_abbrv(c):\n",
    "    '''Gene/protein/chemical name'''\n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"\\d+\",lemma) else 0\n",
    "\n",
    "def LF_base_pair_seq(c): \n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"^[GACT]{2,}$\",lemma) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For a few more examples of LFs of this style that we'll use, see [Disease_Tagging_Tutorial_LFs.py](Disease_Tagging_Tutorial_LFs.py).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maintain a list of all LFs for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Disease_Tagging_Tutorial_LFs import *\n",
    "\n",
    "LFs_doc = [LF_undefined_abbreviation]\n",
    "\n",
    "LFs_sent = [LF_contiguous_mentions]\n",
    "\n",
    "LFs_mention = [LF_tumors_growths,\n",
    "               LF_cancer,\n",
    "               LF_disease_syndrome,\n",
    "               LF_indicators,\n",
    "               LF_common_disease,\n",
    "               LF_common_disease_acronyms,\n",
    "               LF_deficiency_of,\n",
    "               LF_positive_indicator,\n",
    "               LF_left_positive_argument,\n",
    "               LF_right_negative_argument,\n",
    "               LF_medical_afixes,\n",
    "               LF_adj_diseases\n",
    "              ]\n",
    "\n",
    "LFs_dicts =  [LF_SNOWMED_CT_sign_or_symptom,\n",
    "              LF_SNOWMED_CT_disease_or_syndrome,\n",
    "              LF_MESH_disease_or_syndrome,\n",
    "              LF_MESH_sign_or_symptom\n",
    "            ]\n",
    "\n",
    "LFs_false = [LF_chemical_name,\n",
    "             LF_organs,\n",
    "             LF_bodysym,\n",
    "             LF_protein_chemical_abbrv,\n",
    "             LF_base_pair_seq,\n",
    "             LF_too_vague,\n",
    "             LF_neg_surfix,\n",
    "             LF_non_common_disease,\n",
    "             LF_non_disease_acronyms,\n",
    "             LF_pos_in,\n",
    "             LF_gene_chromosome_link,\n",
    "             LF_right_window_incomplete,\n",
    "             LF_negative_indicator\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Labeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct a `CandidateLabeler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the `CandidateLabeler` to to apply the labeling functions to the training `CandidateSet`.  We'll start with some of our labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 10min 20s, sys: 18.7 s, total: 10min 38s\n",
      "Wall time: 10min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<30067x29 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 18114 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFs = LFs_mention + LFs_dicts + LFs_false\n",
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** load if we've already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.load(session, train, 'LF Labels')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add or rerun a single labeling function (or more!) with the below command. Note that we set the argument `expand_key_set` to `True` to indicate that the set of matrix columns should be allowed to expand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<30067x31 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 20964 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFs_2   = LFs_doc + LFs_sent\n",
    "L_train = label_manager.update(session, train, 'LF Labels', True, f=LFs_2)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view statistics about the resulting label matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflicts</th>\n",
       "      <th>coverage</th>\n",
       "      <th>j</th>\n",
       "      <th>overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_tumors_growths</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_cancer</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_disease_syndrome</th>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_indicators</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_common_disease</th>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_common_disease_acronyms</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_deficiency_of</th>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive_indicator</th>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.036651</td>\n",
       "      <td>7</td>\n",
       "      <td>0.018392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_left_positive_argument</th>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.009645</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_right_negative_argument</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_medical_afixes</th>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_adj_diseases</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_SNOWMED_CT_sign_or_symptom</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_SNOWMED_CT_disease_or_syndrome</th>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>13</td>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_MESH_disease_or_syndrome</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>14</td>\n",
       "      <td>0.002461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_MESH_sign_or_symptom</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_chemical_name</th>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.115708</td>\n",
       "      <td>16</td>\n",
       "      <td>0.020122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_organs</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_bodysym</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>18</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_protein_chemical_abbrv</th>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.034589</td>\n",
       "      <td>19</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_base_pair_seq</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_too_vague</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>21</td>\n",
       "      <td>0.020787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_surfix</th>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.157548</td>\n",
       "      <td>22</td>\n",
       "      <td>0.052416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_non_common_disease</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>23</td>\n",
       "      <td>0.021286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_non_disease_acronyms</th>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_pos_in</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_gene_chromosome_link</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>26</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_right_window_incomplete</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_negative_indicator</th>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.099578</td>\n",
       "      <td>28</td>\n",
       "      <td>0.042971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_undefined_abbreviation</th>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>29</td>\n",
       "      <td>0.003825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_contiguous_mentions</th>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.075165</td>\n",
       "      <td>30</td>\n",
       "      <td>0.027206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   conflicts  coverage   j  overlaps\n",
       "LF_tumors_growths                   0.000033  0.000632   0  0.000632\n",
       "LF_cancer                           0.000299  0.001563   1  0.000333\n",
       "LF_disease_syndrome                 0.000765  0.006419   2  0.004423\n",
       "LF_indicators                       0.000133  0.000333   3  0.000266\n",
       "LF_common_disease                   0.001696  0.019723   4  0.009545\n",
       "LF_common_disease_acronyms          0.000366  0.002794   5  0.001596\n",
       "LF_deficiency_of                    0.000366  0.001962   6  0.001929\n",
       "LF_positive_indicator               0.006419  0.036651   7  0.018392\n",
       "LF_left_positive_argument           0.001330  0.009645   8  0.004956\n",
       "LF_right_negative_argument          0.000133  0.000632   9  0.000399\n",
       "LF_medical_afixes                   0.005621  0.027306  10  0.010809\n",
       "LF_adj_diseases                     0.000133  0.000599  11  0.000366\n",
       "LF_SNOWMED_CT_sign_or_symptom       0.000033  0.000565  12  0.000466\n",
       "LF_SNOWMED_CT_disease_or_syndrome   0.000765  0.004789  13  0.004224\n",
       "LF_MESH_disease_or_syndrome         0.000399  0.002461  14  0.002461\n",
       "LF_MESH_sign_or_symptom             0.000000  0.000399  15  0.000333\n",
       "LF_chemical_name                    0.000865  0.115708  16  0.020122\n",
       "LF_organs                           0.000000  0.001330  17  0.001330\n",
       "LF_bodysym                          0.000000  0.005222  18  0.003858\n",
       "LF_protein_chemical_abbrv           0.000466  0.034589  19  0.005488\n",
       "LF_base_pair_seq                    0.000000  0.000100  20  0.000033\n",
       "LF_too_vague                        0.000998  0.041574  21  0.020787\n",
       "LF_neg_surfix                       0.005089  0.157548  22  0.052416\n",
       "LF_non_common_disease               0.000100  0.024346  23  0.021286\n",
       "LF_non_disease_acronyms             0.000266  0.002993  24  0.001297\n",
       "LF_pos_in                           0.000000  0.000000  25  0.000000\n",
       "LF_gene_chromosome_link             0.000067  0.002428  26  0.001131\n",
       "LF_right_window_incomplete          0.000067  0.000565  27  0.000299\n",
       "LF_negative_indicator               0.003625  0.099578  28  0.042971\n",
       "LF_undefined_abbreviation           0.000466  0.019623  29  0.003825\n",
       "LF_contiguous_mentions              0.005554  0.075165  30  0.027206"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Generative Model\n",
    "We estimate the accuracies of the labeling functions without supervision. Specifically, we estimate the parameters of a `NaiveBayes` generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t30067\n",
      "Features:\t\t\t31\n",
      "================================================================================\n",
      "Begin training for rate=1e-05, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.087314\n",
      "\tLearning epoch = 250\tGradient mag. = 0.091899\n",
      "\tLearning epoch = 500\tGradient mag. = 0.091889\n",
      "\tLearning epoch = 750\tGradient mag. = 0.091878\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.091868\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.091857\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.091847\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.091836\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.091826\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.091815\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.091805\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.091794\n",
      "Final gradient magnitude for rate=1e-05, mu=1e-06: 0.092\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=3000, rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.save(session, 'Generative Params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model\n",
    "We use the estimated probabilites to train a discriminative model that classifies each `Candidate` as a true or false mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t16273\n",
      "Features:\t\t\t498874\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 11279.584069\tGradient magnitude = 4881.697678\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 61906.164538\tGradient magnitude = 7071.666546\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 19753.175291\tGradient magnitude = 11571.749663\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 36626.160197\tGradient magnitude = 6708.626301\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 13853.509507\tGradient magnitude = 8466.611779\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 13104.102481\tGradient magnitude = 8038.676338\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 15781.550772\tGradient magnitude = 5265.207214\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 10908.850391\tGradient magnitude = 3606.274265\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 11774.293235\tGradient magnitude = 4168.907261\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 10615.808522\tGradient magnitude = 3591.072159\n",
      "\tLearning epoch = 1000\tStep size = 0.000367695424771\n",
      "\tLoss = 9653.008503\tGradient magnitude = 2758.497692\n",
      "\tLearning epoch = 1100\tStep size = 0.000332687932862\n",
      "\tLoss = 8916.873077\tGradient magnitude = 1262.928380\n",
      "\tLearning epoch = 1200\tStep size = 0.000301013429093\n",
      "\tLoss = 8760.258547\tGradient magnitude = 22.702331\n",
      "\tLearning epoch = 1300\tStep size = 0.000272354586819\n",
      "\tLoss = 8747.525358\tGradient magnitude = 19.006806\n",
      "\tLearning epoch = 1400\tStep size = 0.000246424291385\n",
      "\tLoss = 8739.171257\tGradient magnitude = 16.363050\n",
      "\tLearning epoch = 1500\tStep size = 0.000222962763703\n",
      "\tLoss = 8733.421210\tGradient magnitude = 14.375776\n",
      "\tLearning epoch = 1600\tStep size = 0.000201734957697\n",
      "\tLoss = 8729.316770\tGradient magnitude = 12.838859\n",
      "\tLearning epoch = 1700\tStep size = 0.000182528205523\n",
      "\tLoss = 8726.297932\tGradient magnitude = 11.625911\n",
      "\tLearning epoch = 1800\tStep size = 0.000165150086984\n",
      "\tLoss = 8724.020926\tGradient magnitude = 10.653538\n",
      "\tLearning epoch = 1900\tStep size = 0.000149426501798\n",
      "\tLoss = 8722.267137\tGradient magnitude = 9.864327\n",
      "\tLearning epoch = 2000\tStep size = 0.000135199925397\n",
      "\tLoss = 8720.892170\tGradient magnitude = 9.217377\n",
      "\tLearning epoch = 2100\tStep size = 0.00012232783079\n",
      "\tLoss = 8719.797821\tGradient magnitude = 8.682832\n",
      "\tLearning epoch = 2200\tStep size = 0.000110681260672\n",
      "\tLoss = 8718.915451\tGradient magnitude = 8.238486\n",
      "\tLearning epoch = 2300\tStep size = 0.000100143535489\n",
      "\tLoss = 8718.196574\tGradient magnitude = 7.867606\n",
      "\tLearning epoch = 2400\tStep size = 9.06090844946e-05\n",
      "\tLoss = 8717.605986\tGradient magnitude = 7.557452\n",
      "\tLearning epoch = 2500\tStep size = 8.19823881078e-05\n",
      "\tLoss = 8717.117907\tGradient magnitude = 7.298324\n",
      "\tLearning epoch = 2600\tStep size = 7.41770209616e-05\n",
      "\tLoss = 8716.713021\tGradient magnitude = 7.082673\n",
      "\tLearning epoch = 2700\tStep size = 6.71147860624e-05\n",
      "\tLoss = 8716.376410\tGradient magnitude = 6.904434\n",
      "\tLearning epoch = 2800\tStep size = 6.07249313844e-05\n",
      "\tLoss = 8716.096658\tGradient magnitude = 6.758834\n",
      "\tLearning epoch = 2900\tStep size = 5.49434410507e-05\n",
      "\tLoss = 8715.864827\tGradient magnitude = 6.642045\n",
      "\tLearning epoch = 3000\tStep size = 4.9712393998e-05\n",
      "\tLoss = 8715.673911\tGradient magnitude = 6.550866\n",
      "\tLearning epoch = 3100\tStep size = 4.49793837036e-05\n",
      "\tLoss = 8715.518463\tGradient magnitude = 6.482919\n",
      "\tLearning epoch = 3200\tStep size = 4.06969931571e-05\n",
      "\tLoss = 8715.393949\tGradient magnitude = 6.436070\n",
      "\tLearning epoch = 3300\tStep size = 3.68223198197e-05\n",
      "\tLoss = 8715.296840\tGradient magnitude = 6.408689\n",
      "\tLearning epoch = 3400\tStep size = 3.33165458113e-05\n",
      "\tLoss = 8715.224037\tGradient magnitude = 6.399083\n",
      "\tLearning epoch = 3500\tStep size = 3.01445490191e-05\n",
      "\tLoss = 8715.173156\tGradient magnitude = 6.406214\n",
      "\tLearning epoch = 3600\tStep size = 2.72745512307e-05\n",
      "\tLoss = 8715.142294\tGradient magnitude = 6.429169\n",
      "\tLearning epoch = 3700\tStep size = 2.46777997696e-05\n",
      "\tLoss = 8715.129907\tGradient magnitude = 6.467109\n",
      "\tLearning epoch = 3800\tStep size = 2.23282794396e-05\n",
      "\tLoss = 8715.134551\tGradient magnitude = 6.519148\n",
      "\tLearning epoch = 3900\tStep size = 2.02024518955e-05\n",
      "\tLoss = 8715.154936\tGradient magnitude = 6.584617\n",
      "\tLearning epoch = 4000\tStep size = 1.82790198275e-05\n",
      "\tLoss = 8715.190154\tGradient magnitude = 6.662816\n",
      "\tLearning epoch = 4100\tStep size = 1.65387135968e-05\n",
      "\tLoss = 8715.239375\tGradient magnitude = 6.753220\n",
      "\tLearning epoch = 4200\tStep size = 1.49640981858e-05\n",
      "\tLoss = 8715.301995\tGradient magnitude = 6.855328\n",
      "\tLearning epoch = 4300\tStep size = 1.35393985271e-05\n",
      "\tLoss = 8715.377447\tGradient magnitude = 6.968815\n",
      "\tLearning epoch = 4400\tStep size = 1.2250341464e-05\n",
      "\tLoss = 8715.465122\tGradient magnitude = 7.093108\n",
      "\tLearning epoch = 4500\tStep size = 1.10840127561e-05\n",
      "\tLoss = 8715.564634\tGradient magnitude = 7.228220\n",
      "\tLearning epoch = 4600\tStep size = 1.00287277002e-05\n",
      "\tLoss = 8715.675582\tGradient magnitude = 7.373671\n",
      "\tLearning epoch = 4700\tStep size = 9.0739140687e-06\n",
      "\tLoss = 8715.797673\tGradient magnitude = 7.529209\n",
      "\tLearning epoch = 4800\tStep size = 8.21000619294e-06\n",
      "\tLoss = 8715.930883\tGradient magnitude = 7.694542\n",
      "\tLearning epoch = 4900\tStep size = 7.42834913113e-06\n",
      "\tLoss = 8716.074832\tGradient magnitude = 7.869590\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=5000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498874,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 5.44 s, total: 1min 52s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Development `CandidateSet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create features for the development set.\n",
    "\n",
    "Note that we use the training features feature set, because those are the only features for which we have learned parameters. Features that were not encountered during training, e.g., a token that does not appear in the training set, are ignored, because we do not have any information about them.\n",
    "\n",
    "To do so with the `FeatureManager`, we call update with the new `CandidateSet`, the name of the training `AnnotationKeySet`, and the value `False` for the parameter `extend_key_set` to indicate that the `AnnotationKeySet` should not be expanded with new `Feature` keys encountered during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 14min 39s, sys: 29.8 s, total: 15min 9s\n",
      "Wall time: 23min 14s\n"
     ]
    }
   ],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the development set labels and gold candidates we made in Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_gold_dev = label_manager.load(session, dev, \"Development Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_dev_set = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the discriminative model on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tp, fp, tn, fn = disc_model.score(F_dev, L_gold_dev, gold_dev_set)\n",
    "tp, fp, tn, fn = disc_model.score(F_dev, L_gold_dev, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prec = len(tp) / float(len(tp) + len(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recall = len(tp) / float(len(tp) + len(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5405405405405406"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = (2*prec*recall) / (prec+recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Examples\n",
    "After evaluating on the development `CandidateSet`, the labeling functions can be modified. Try changing the labeling functions to improve performance. You can view the true positives, false positives, true negatives, and false negatives using the `Viewer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# NOTE: This if-then statement is only to avoid opening the viewer during automated testing of this notebook\n",
    "# You should ignore this!\n",
    "import os\n",
    "if 'CI' not in os.environ:\n",
    "    sv = SentenceNgramViewer(tp, session, annotator_name=\"Tutorial Part IV User\")\n",
    "else:\n",
    "    sv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part V, we will test our model on the test `CandidateSet`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
